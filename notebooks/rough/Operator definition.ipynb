{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import HDFStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HDF_reader(file_location, df_name):\n",
    "    store = HDFStore(file_location)\n",
    "    data = input_store.get(df_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def csv_reader(file_location):\n",
    "    data = pd.read_csv(file_location)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HDF_writer(df, file_location, reference):\n",
    "    store = HDFStore(file_location)\n",
    "    store.open()\n",
    "    store.put(reference, df, 't')\n",
    "    store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operator definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Splitter():\n",
    "\n",
    "    def __init__(self, file_location, output_location, test_size):\n",
    "        self.file_location = file_location \n",
    "        self.output_location = output_location # can be given default value\n",
    "        self.test_size = test_size # to be unpacked from node configuration yaml\n",
    "\n",
    "    def input(self): \n",
    "        return csv_reader(self.file_location)\n",
    "\n",
    "    def output(self):\n",
    "        return {'train': lambda x: HDF_writer(x, self.output_location, 'train'),\n",
    "                'test': lambda x: HDF_writer(x, self.output_location, 'test')}\n",
    "\n",
    "    def run(self):\n",
    "        df = self.input()\n",
    "\n",
    "        train, test = train_test_split(self.input(), test_size= self.test_size)\n",
    "\n",
    "        self.output()['train'](train)\n",
    "        self.output()['test'](test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(file_location='/home/sanjay/Documents/Iris/Iris_data/Iris.csv'\n",
    "                    ,output_location='/home/sanjay/Documents/Iris/Iris_data/chk.h5'\n",
    "                   ,test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = HDFStore('/home/sanjay/Documents/Iris/Iris_data/chk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"<class 'pandas.io.pytables.HDFStore'>\\nFile path: /home/sanjay/Documents/Iris/Iris_data/chk.h5\\n/test             frame_table  (typ->appendable,nrows->30,ncols->6,indexers->[index]) \\n/train            frame_table  (typ->appendable,nrows->120,ncols->6,indexers->[index])\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class KFold_splitter():\n",
    "    \n",
    "    def __init__(self, file_location, output_location, n_splits):\n",
    "        self.file_location = file_location \n",
    "        self.output_location = output_location # can be given default value\n",
    "        self.n_splits = n_splits # to be unpacked from node configuration yaml\n",
    "\n",
    "    def input(self): \n",
    "        return csv_reader(self.file_location)\n",
    "\n",
    "    def output(self):\n",
    "        out = {}\n",
    "        \n",
    "        for i in range(self.n_splits):\n",
    "            train_df_name = 'train_{}'.format(i)\n",
    "            test_df_name = 'test_{}'.format(i)\n",
    "            out[train_df_name]= lambda x,ref=train_df_name: HDF_writer(x, self.output_location, ref)\n",
    "            out[test_df_name]= lambda x,ref=test_df_name: HDF_writer(x, self.output_location, ref)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def run(self):\n",
    "        df = self.input()\n",
    "        kf = KFold(n_splits= self.n_splits, shuffle= True)\n",
    "\n",
    "        n= 0\n",
    "        for train_index, test_index in kf.split(df):\n",
    "            train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "            self.output()['train_{}'.format(n)](train)\n",
    "            self.output()['test_{}'.format(n)](test)\n",
    "            n= n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_splitter = KFold_splitter(file_location='/home/sanjay/Documents/Iris/Iris_data/Iris.csv'\n",
    "                    ,output_location='/home/sanjay/Documents/Iris/Iris_data/chk1.h5'\n",
    "                   ,n_splits= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_splitter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = HDFStore('/home/sanjay/Documents/Iris/Iris_data/chk1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"<class 'pandas.io.pytables.HDFStore'>\\nFile path: /home/sanjay/Documents/Iris/Iris_data/chk1.h5\\n/test_0             frame_table  (typ->appendable,nrows->75,ncols->6,indexers->[index])\\n/test_1             frame_table  (typ->appendable,nrows->75,ncols->6,indexers->[index])\\n/train_0            frame_table  (typ->appendable,nrows->75,ncols->6,indexers->[index])\\n/train_1            frame_table  (typ->appendable,nrows->75,ncols->6,indexers->[index])\""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
